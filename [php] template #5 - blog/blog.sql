-- phpMyAdmin SQL Dump
-- version 4.9.0.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1:3306
-- Generation Time: Oct 27, 2020 at 05:55 PM
-- Server version: 8.0.15
-- PHP Version: 7.1.32

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET AUTOCOMMIT = 0;
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `blog`
--

-- --------------------------------------------------------

--
-- Table structure for table `articlecategory`
--

CREATE TABLE `articlecategory` (
  `id` int(10) UNSIGNED NOT NULL,
  `articleid` int(10) UNSIGNED NOT NULL,
  `categoryid` int(10) UNSIGNED NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- Dumping data for table `articlecategory`
--

INSERT INTO `articlecategory` (`id`, `articleid`, `categoryid`) VALUES
(1, 3, 1),
(8, 8, 6),
(9, 10, 5),
(10, 11, 8),
(11, 3, 7),
(13, 7, 7),
(14, 8, 7),
(16, 10, 7),
(17, 11, 7),
(18, 16, 7),
(19, 17, 7),
(35, 3, 2),
(80, 57, 1);

-- --------------------------------------------------------

--
-- Table structure for table `articles`
--

CREATE TABLE `articles` (
  `id` int(255) UNSIGNED NOT NULL,
  `title` varchar(100) NOT NULL,
  `author` varchar(50) NOT NULL,
  `datepublished` date NOT NULL,
  `img` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,
  `description` text NOT NULL,
  `content` mediumtext NOT NULL,
  `active` tinyint(1) NOT NULL,
  `datalastedit` date DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- Dumping data for table `articles`
--

INSERT INTO `articles` (`id`, `title`, `author`, `datepublished`, `img`, `description`, `content`, `active`, `datalastedit`) VALUES
(3, 'Объектно-ориентированный JavaScript простыми словами', 'Zell Liew', '2020-10-06', 'https://habrastorage.org/webt/ig/mq/2d/igmq2dvqrh3pvqpohaicef0c3zi.png', 'Доброго времени суток, друзья!\r\n\r\nВ JavaScript существует 4 способа создать объект:\r\n\r\nФункция-контруктор (constructor function)\r\nКласс (class)\r\nСвязывание объектов (object linking to other object, OLOO)\r\nФабричная функция (factory function)\r\n\r\nКакой метод следует использовать? Какой из них является лучшим?\r\n\r\nДля того, чтобы ответить на эти вопросы мы не только рассмотрим каждый подход в отдельности, но и сравним между собой классы и фабричные функции по следующим критериям: наследование, инкапсуляция, ключевое слово «this», обработчики событий.\r\n\r\nДавайте начнем с того, что такое объектно-ориентированное программирование (ООП).', '<br>\r\nДоброго времени суток, друзья!<br>\r\n<br>\r\nПредставляю вашему вниманию перевод замечательной статьи Джейка Арчибальда «Offline Cookbook», посвященной различным вариантам использования сервис-воркера (ServiceWorker API, далее по тексту — просто воркер) и интерфейса кэширования (Cache API).<br>\r\n<br>\r\nПредполагается, что вы знакомы с основами названных технологий, потому что кода будет много, а слов мало.<br>\r\n<br>\r\nЕсли не знакомы, то начните с <a href=\"https://developer.mozilla.org/ru/docs/Web/API/ServiceWorker\" rel=\"nofollow\">MDN</a>, а затем возвращайтесь. Вот еще неплохая <a href=\"https://habr.com/ru/post/491840/\">статья про сервис-воркеры</a> специально для визуалов.<br>\r\n<br>\r\nБез дальнейших предисловий.<br>\r\n<a name=\"habracut\"></a><br>\r\n<h3>В какой момент сохранять ресурсы?</h3><br>\r\nВоркер позволяет обрабатывать запросы независимо от кэша, поэтому будем рассматривать их по-отдельности.<br>\r\n<br>\r\nПервый вопрос: когда следует кэшировать ресурсы?<br>\r\n<br>\r\n<h5>При установке как зависимость</h5><br>\r\n<br>\r\n<br>\r\nОдним из событий, возникающих при работе воркера, является событие install. Это событие можно использовать для подготовки к обработке других событий. При установке нового воркера старый продолжает обслуживать страницу, так что обработка события install не должна нарушить его работу.<br>\r\n<br>\r\n<strong>Подходит для</strong> кэширования стилей, изображений, скриптов, шаблонов… в общем, для любых статических файлов, используемых на странице.<br>\r\n<br>\r\nРечь идет о тех файлах, без которых приложение не сможет работать подобно файлам, включаемым в начальную загрузку нативных приложений.<br>\r\n<br>\r\n<pre><code class=\"javascript\">self.addEventListener(\'install\', event =&gt; {\r\n    event.waitUntil(\r\n        caches.open(\'mysite-static-v3\')\r\n            .then(cache =&gt; cache.addAll([\r\n                \'/css/whatever-v3.css\',\r\n                \'/css/imgs/sprites-v6.png\',\r\n                \'/css/fonts/whatever-v8.woff\',\r\n                \'/js/all-min-v4.js\'\r\n                // и т.д.\r\n            ]))\r\n    )\r\n})\r\n</code></pre><br>\r\nevent.waitUntil принимает промис для определения продолжительности и результата установки. Если промис будет отклонен, воркер не будет установлен. caches.open и cache.addAll возвращают промисы. Если один из ресурсов не будет получен,<br>\r\nвызов cache.addAll будет отклонен.<br>\r\n<br>\r\n<h5>При установке не как зависимость</h5><br>\r\n<br>\r\n<br>\r\nЭто похоже на предыдущий пример, но в данном случае мы не ожидаем завершения установки, поэтому это не приведет к ее отмене.<br>\r\n<br>\r\n<strong>Подходит для</strong> больших ресурсов, которые не требуются прямо сейчас, например, ресурсы для поздних уровней игры.<br>\r\n<br>\r\n<pre><code class=\"javascript\">self.addEventListener(\'install\', event =&gt; {\r\n    event.waitUntil(\r\n        caches.open(\'mygame-core-v1\')\r\n            .then(cache =&gt; {\r\n                cache.addAll(\r\n                    // уровни 11-20\r\n                )\r\n                return cache.addAll(\r\n                    // ключевые ресурсы и уровни 1-10\r\n                )\r\n            })\r\n    )\r\n})\r\n</code></pre><br>', 1, NULL),
(7, 'Вред хранимых процедур', 'RUVDS.com', '2020-10-05', 'https://habrastorage.org/webt/re/oy/_0/reoy_0krsawhg3elvezfzuqjone.jpeg', 'В чат подкаста «Цинковый прод» скинули статью о том, как некие ребята перенесли всю бизнес-логику в хранимые процедуры на языке pl/pgsql. И так как у статьи было много плюсов, то значит, есть люди, а может быть, их даже большинство, которые положительно восприняли такой рефакторинг.\r\n\r\nЯ не буду растекаться мысью по древу, а сразу накидаю кучку минусов использования хранимых процедур.', 'В чат подкаста <a href=\"https://www.youtube.com/channel/UC6cTShKx3lJWw-EzSr_ZAfw/videos?view=0&amp;sort=p&amp;flow=grid\">«Цинковый прод»</a> скинули <a href=\"https://habr.com/ru/company/lingualeo/blog/515530/\">статью</a> о том, как некие ребята перенесли всю бизнес-логику в хранимые процедуры на языке pl/pgsql. И так как у статьи было много плюсов, то значит, есть люди, а может быть, их даже большинство, которые положительно восприняли такой рефакторинг. <br>\r\n<br>\r\nЯ не буду растекаться мысью по древу, а сразу накидаю кучку минусов использования хранимых процедур.<br>\r\n<a name=\"habracut\"></a><br>\r\n<h2><font color=\"#3AC1EF\">Минусы хранимых процедур</font></h2><br>\r\n<h3><font color=\"#3AC1EF\">Версионирование</font></h3><br>\r\nЕсли в случае с кодом на php вы можете просто переключиться в git на другую ветку и посмотреть, что получилось, то хранимые процедуры нужно еще засунуть в базу. И традиционные миграции тут плохо помогут: если записывать все изменения хранимок как новый CREATE OR REPLACE PROCEDURE, то на кодревью будет ад: всегда новый файл, который непонятно с чем сравнивать. Поэтому придется искать какие-то дополнительные инструменты или писать свой велосипед.<br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Сам язык pl/pgsql</font></h3><br>\r\nЭто устаревший процедурный язык из девяностых, который вообще никак не развивается. Никакого ООП или ФП или чего бы то ни было. Синтаксис без малейшего намека на синтаксический сахар. <br>\r\n<br>\r\nНапример, переменные нужно объявлять в начале процедуры, в специальном блоке DECLARE. Так делали наши деды, в этом есть некая ностальгия по языку Pascal, но спасибо, не в 2020.<br>\r\n<br>\r\nСравните две функции, которые делают одно и то же на php и pl/pgsql:<br>\r\n<br>\r\n<pre><code class=\"pgsql\">CREATE OR REPLACE FUNCTION sum(x int, y int)\r\n    RETURNS int\r\n    LANGUAGE plpgsql\r\nAS $$\r\nDECLARE\r\n    result int;\r\nBEGIN\r\n    result := x + y;\r\n    return result;\r\nEND;\r\n$$;\r\n</code></pre><br>\r\n<pre><code class=\"php\">function sum(int $x, int $y): int\r\n{\r\n    $result = $x + $y;\r\n    return $result;\r\n}\r\n</code></pre><br>\r\nПримерно в 2-3 раза больше писанины.<br>\r\n<br>\r\nКроме того, язык интерпретируемый, без JIT и т.д. (поправьте меня, если что-то изменилось в последних версиях). Т.е. все очень медленно и печально. Уж если использовать какие-то хранимки, то на чистом SQL или v8 (т.е. javascript).<br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Отладка</font></h3><br>\r\nПоверьте, отлаживать код на php в 100500 раз проще. Ты просто поправил что-то и смотришь результат. Можно обложить echo или смотреть, что там через xdebug прямо в IDE. <br>\r\n<br>\r\nОтладка хранимых процедур — это неудобно. Это надо делать в pgadmin (включив специальное расширение). PgAdmin — это далеко не PHPstorm по удобству.<br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Логирование и обработка ошибок</font></h3><br>\r\nЗабудьте о том, чтобы красивый json c трейсом падал с stdout, а потом в graylog и в sentry. И чтобы все это автоматически происходило, выдавая пользователю ошибку 500, в случае если контроллер не поймал exception.<br>\r\n <br>\r\n В хранимках pl/pgsql вы всё будете делать вручную:<br>\r\n<br>\r\n<code>GET DIAGNOSTICS stack = PG_CONTEXT;<br>\r\nRAISE NOTICE E\'--- Стек вызова ---\\n%\', stack;<br>\r\n</code><br>\r\n<h3><font color=\"#3AC1EF\">Сбор метрик</font></h3><br>\r\nВы не можете, как в golang, просто добавить эндпоинт /metrics, который будет подсасываться Прометеусом, куда вы напихаете бизнесовые и другие метрики для мониторинга. Я просто не знаю, как тут выкрутиться с pl/pgsql. <br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Масштабирование</font></h3><br>\r\nВыполнение хранимых процедур тратит ресурсы (например, CPU) сервера базы данных. В случае других языков вы можете вынести логику на другие ноды. <br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Зависимости</font></h3><br>\r\nВ php вы, используя пакетный менеджер composer, одним движением можете подтянуть нужную библиотеку из интернета. Точно так же как в js это будет npm, в Rust это будет cargo и т.д. <br>\r\n<br>\r\nВ мире pl/pgsql нужно страдать. В этом языке просто нет менеджера зависимостей. <br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Фреймворки</font></h3><br>\r\nВ современном мире веб-приложение часто не пишут с нуля, а собирают на основе фреймворка, используя его компоненты. К примеру, на Laravel у вас из коробки есть роутинг, валидация запроса, движок шаблонов, аутентификация/авторизация, 100500 хелперов на все случаи жизни и т.д. Писать всё это вручную с нуля, на устаревшем языке — ну нет, спасибо. <br>\r\n<br>\r\nПолучится много велосипедов, которые потом еще и поддерживать придется.<br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Юнит-тесты</font></h3><br>\r\nСложно даже представить, как удобно организовать unit-тесты в хранимках на pl/pgsql. Я ни разу не пробовал. Поделитесь пожалуйста в комментариях.<br>\r\n<br>\r\n<h3><font color=\"#3AC1EF\">Рефакторинг</font></h3><br>\r\nНесмотря на то, что существует IDE для работы с базой данных (Datagrip), для обычных языков средства рефакторинга гораздо богаче. Всевозможные линтеры, подсказки по упрощению кода и т.д.<br>\r\n<br>\r\nМаленький пример: в тех кусках кода, которые я привел в начале статьи, PHPStorm дал подсказку, что переменная <code>$result</code> необязательна, и можно просто сделать <code>return $x + $y;</code><br>\r\n<br>\r\nВ случае с plpgsql — тишина. <br>\r\n<br>\r\n<h2><font color=\"#3AC1EF\">Плюсы хранимых процедур</font></h2><br>\r\n<ol>\r\n<li>Нет оверхеда на перегон промежуточных данных по пути бекенд-БД.</li>\r\n<li>В хранимых процедурах кешируется план запроса, что может сэкономить пару ms. т.е. как обертка над запросом иногда это имеет смысл делать (в редких случаях и не на pl/pgsql, а на голом sql), если бешеный хайлоад, а сам запрос выполняется быстро.</li>\r\n<li>Когда пишешь свой extension к посгресу — без хранимок не обойтись.</li>\r\n<li>Когда хочешь из соображений безопасности спрятать какие-то данные, дав доступ приложению только к одной-двум хранимкам (редкий кейс).</li>\r\n</ol><br>\r\n<h2><font color=\"#3AC1EF\">Выводы</font></h2><br>\r\nНа мой взгляд, хранимые процедуры нужны только в очень-очень редких случаях, когда вы уверены, что вы без них вообще не можете обойтись. В остальных кейсах — вы только усложните жизнь разработчикам, причем существенно. <br>\r\n<br>\r\nЯ бы понял, если в исходной статье часть логики переложили на SQL, это можно понять. Но зачем хранимки — это загадка.<br>\r\n<br>\r\nБуду рад, если вы считаете, что я неправ или знаете, какие-то еще ситуации, связанные с хранимыми процедурами (как плюсы, так и минусы), и напишете об этом в коменты.<br>\r\n<br>', 1, NULL),
(8, 'C2x: будущий стандарт C', 'Badoo', '2020-05-21', 'https://habrastorage.org/webt/7j/dw/5r/7jdw5r9gajn2olyfuypvvwskuve.png', '<blockquote>I strain to make the far-off echo yield<br>\r\nA cue to the events that may come in my day.<br>\r\n(‘Doctor Zhivago’, Boris Pasternak)</blockquote><p>I’ll be honest: I don’t write in pure C that often anymore and I haven’t been following the language’s development for a long time. However, two unexpected things happened recently: С <a href=\"https://www.tiobe.com/tiobe-index/\">won back</a> the title of the most popular programming language according to TIOBE, and the first truly ', '<blockquote>I strain to make the far-off echo yield<br>\r\nA cue to the events that may come in my day.<br>\r\n(‘Doctor Zhivago’, Boris Pasternak)</blockquote><p>I’ll be honest: I don’t write in pure C that often anymore and I haven’t been following the language’s development for a long time. However, two unexpected things happened recently: С <a href=\"https://www.tiobe.com/tiobe-index/\">won back</a> the title of the most popular programming language according to TIOBE, and the first truly <a href=\"https://nostarch.com/Effective_C\">interesting</a> book in years on this language was published. So, I decided to spend a few evenings studying material on C2x, the future version of C.</p><br>\r\n<p>Here I will share with you what I consider to be its most interesting new features.</p><a name=\"habracut\"></a><br>\r\n<h1 id=\"the-committee-the-standard-and-all-that\">The Committee, the Standard and all that</h1><br>\r\n<p>I am sure most of you know how C is developed, but, for anyone who doesn’t know let me first explain the terminology, and will then briefly retell the story of the language.</p><br>\r\n<p>In 1989 the already extremely popular programming language, C, reached new heights of recognition, becoming both the American national (<a href=\"https://en.wikipedia.org/wiki/American_National_Standards_Institute\">ANSI</a>) and the international (<a href=\"https://en.wikipedia.org/wiki/International_Organization_for_Standardization\">ISO</a>) standard. This version of C was known as C89, or ANSI C to differentiate it from the numerous semi-compatible dialects that had existed previously.</p><br>\r\n<p>A new version of the language standard is released approximately once every ten years. At the present time there are four versions in existence: the original C89, C99, C11 and C18. It is not known when the next version will be published, so the version currently being worked on is referred to as C2x.</p><br>\r\n<p>Changes to the standard are made by a special group, the so-called WG14. It comprises interested representatives of the industry from various countries.</p><br>\r\n<p>In the specialist English-language literature this group is often referred to as the ‘Committee’, so that is what I am going to call it here as well.</p><br>\r\n<p>The Committee receives proposals from those involved, each proposal being given a designation(e.g. <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2353.htm\">N2353</a>). Proposals usually include: the reason for introducing changes, references to other documents, and specific changes to the Standard. Proposals can come in several versions, each of which is given a unique designation.</p><br>\r\n<p>Returning to our topic for a moment, I have split this article into three parts, and have ordered them according to the likelihood of the relevant changes being made to the standard. The three parts are as follows:</p><br>\r\n<ol>\r\n<li>Proposals the Committee has already accepted.</li>\r\n<li>Proposals received positively but returned to the authors for revision.</li>\r\n<li>What I consider to be the ‘juiciest’ proposals: rumoured unpublished proposals, being discussed behind the scenes by members of the Committee.</li>\r\n</ol><br>\r\n<h1 id=\"proposals-accepted-by-the-committee\">Proposals accepted by the Committee</h1><br>\r\n<h3 id=\"strdup-and-strndup-functions\">strdup and strndup functions</h3><br>\r\n<p>I may appear ignorant when I say that I wasn’t aware these functions weren’t in the standard C library. What could be more obvious and simpler than copying strings? But no, C isn’t like that. C doesn’t like its users.</p><br>\r\n<p>So, 20 years later, we are <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2353.htm\">getting</a> the <code>strdup</code> and <code>strndup</code> functions!</p><br>\r\n<pre><code class=\"cpp\">#include <string.h>\r\n\r\nchar *strdup (const char *s);\r\nchar *strndup (const char *s, size_t size);</code></pre><br>\r\n<p>It is nice to know that even the Committee accepts the inevitable.</p><br>\r\n<h3 id=\"attributes\">Attributes</h3><br>\r\n<p>Developers of major C compilers have a favourite game they play: coming up with extensions to the language most often expressed through attributes of declarations and definitions. The language itself, of course, does not provide any special syntax for such things, so each person needs to do what they can to be creative.</p><br>\r\n<p>In order to – somehow – to sort out this mess without coming up with dozens of new keywords, the Committee thought up a syntax-to-rule-them-all. In a nutshell, a standard <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2335.pdf\">syntax</a> for specifying attributes will be approved as part of the next version. Here is an example from the proposal:</p><br>\r\n<pre><code class=\"cpp\">[[attr1]] struct [[attr2]] S { } [[attr3]] s1 [[attr4]], s2 [[attr5]];</code></pre><br>\r\n<p>Here, <code>attr1</code> relates to <code>s1</code> and <code>=s2=</code>; <code>attr2</code> relates to the <code>struct S</code> definition; <code>attr3</code> relates to the <code>struct s1</code> type; <code>attr4</code> to the <code>s1</code> identifier; and <code>attr5</code> to the <code>s2</code> identifier.</p><br>\r\n<p>The Committee has already voted to include the attributes in the standard, but there is still a long time to wait before the updated version of the standard is published. Nevertheless, proposal authors are already playing with their new toy. Here are some of the proposed attributes:</p><br>\r\n<ol>\r\n<li>The <code>deprecated</code> attribute allows you to mark a declaration as obsolete, which allows compilers to issue appropriate warnings.</li>\r\n<li>The <code>fallthrough</code> attribute can be used to explicitly mark the places in the switch case branches, where the control flow is supposed to cross case boundaries.</li>\r\n<li>Using the <code>nodiscard</code> attribute you can explicitly specify that a value returned by the function needs to be processed.</li>\r\n<li>Where a variable or function is not used deliberately, you can mark it with the <code>maybe_unused</code> attribute (instead of the idiomatic <code>(void) unused_var</code>).</li>\r\n<li>A function not returning to the call location can be marked with the <code>noreturn</code> attribute.</li>\r\n</ol><br>\r\n<h3 id=\"old-school-function-parameter-declaration-style-kr\">Old-school function parameter declaration style (K&R)</h3><br>\r\n<p>‘K&R declaration’ (read “when types are specified after the brackets” or, “I don’t understand old code in C”) is a form of function parameter declaration that was already out-of-date way back in 1989. It is finally going to be <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2432.pdf\">burnt with fire</a>. In other words, you won’t be allowed to do this anymore:</p><br>\r\n<pre><code class=\"cpp\">long maxl (a, b)\r\nlong a, b;\r\n{\r\n    return a > b ? a: b;\r\n}</code></pre><br>\r\n<p>Enlightenment has finally come to code in C! Function declarations will at last actually do what people expect them to:</p><br>\r\n<pre><code class=\"cpp\">/* function declaration without arguments */\r\nint no_args();\r\n\r\n/* also function declaration without arguments */\r\nint no_args(void);</code></pre><br>\r\n<h3 id=\"signed-integer-representation\">Signed integer representation</h3><br>\r\n<p>What has felt like an endless saga is nearing completion, it would seem. The Committee has <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2412.pdf\">come to terms</a> with the fact that there are no such things as unicorns or mythical architectures, and programmers in C are dealing with <a href=\"https://en.wikipedia.org/wiki/Two\'s_complement\">Two’s complement</a> signed integer representation.</p><br>\r\n<p>In its present form this clarification simplifies the standard a little, but in future it should make it possible to get rid of the language’s favourite undefined behaviour.</p><br>\r\n<h1 id=\"proposals-being-worked-on\">Proposals being worked on</h1><br>\r\n<p>While it can be said that the changes listed above already exist in our reality, the following group of proposals is still being developed. Nevertheless, the Committee has given them provisional approval and, assuming the authors show due diligence, they should definitely be accepted.</p><br>\r\n<h3 id=\"anonymous-function-parameters\">Anonymous function parameters</h3><br>\r\n<p>I regularly write 1-2 trial programs in C a week. And, quite honestly, I have long grown tired of having to specify the names of unused arguments.</p><br>\r\n<p>Implementing <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2510.pdf\">one</a> of the proposals positively assessed by the Committee would mean that we wouldn’t have to keep specifying the names of parameters in function definitions:</p><br>\r\n<pre><code class=\"cpp\">int main(int, char *[])\r\n{\r\n    /* No hassle! */\r\n    return 0;\r\n}</code></pre><br>\r\n<p>It’s a small thing – but welcome!</p><br>\r\n<h3 id=\"the-old-new-keywords\">The old new keywords</h3><br>\r\n<p>After a very loooong transition period the Committee, finally, decided to accept, erm, <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2458.pdf\">‘new’</a> <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2457.pdf\">keywords</a> into the language: <code>true</code>, <code>false</code>, <code>alignas</code>, <code>alignof</code>, <code>bool</code>, <code>static_assert</code> and others. It will finally be possible to drop headers like <code><stdbool.h></code>.</p><br>\r\n<h3 id=\"including-binary-files-in-the-source-file\">Including binary files in the source file</h3><br>\r\n<p>The <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2499.pdf\">option</a> of including binary data from files in the executable file is something all game developers are going to find unbelievably useful:</p><br>\r\n<pre><code class=\"cpp\">const int music[] = {\r\n   #embed int \"music.wav\"\r\n};</code></pre><br>\r\n<p>It’s my belief that the Committee has realises that the community knows where their next meeting is being held, and that this preprocessor directive will be accepted without questions.</p><br>\r\n<h3 id=\"farewell-null--or-nullptr-ready-on-the-starting-blocks\">Farewell, NULL – or nullptr ready on the starting blocks</h3><br>\r\n<p>It would seem that the problematic <code>NULL</code> macros are being <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2394.pdf\">replaced</a> with the keyword <code>nullptr</code>, which will be equivalent to the expression <code>((void*)0)</code> and, in the case of type conversion, will have to remain a pointer type. Any use of NULL should be accompanied with a compiler warning:</p><br>\r\n<pre><code class=\"cpp\">/* I always forget why the cast is necessary. */\r\nint execl(path, arg1, arg2, (char  *) NULL);\r\n\r\n/* But happiness is just round the corner */\r\nint execl(path, arg1, arg2, nullptr);</code></pre><br>\r\n<p>If this example make no sense to you, then take a look at the Linux documentation under <code>man 3 exec</code> and you will find your enlightenment there.</p><br>\r\n<h3 id=\"reform-of-error-processing-in-the-standard-library\">Reform of error processing in the standard library</h3><br>\r\n<p>The processing of standard library function errors has been a longstanding problem in C. The combination of unfortunate solutions in various versions of the standard, the conservative stance of the Committee and reverse compatibility issues have all got in the way of finding a solution that suits everyone.</p><br>\r\n<p>And here, finally, is someone prepared to <a href=\"http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2429.pdf\">propose</a> a solution for compiler developers, the super-conservative Committee and for us mere mortals:</p><br>\r\n', 1, '2020-10-19'),
(10, 'Под капотом сортировок в STL', 'Mail.ru Group', '2020-09-09', 'https://habrastorage.org/webt/pk/h8/0q/pkh80qxqoj-atzcdxmdfodl0lt0.png', 'Стандарт С++ почти никогда не указывает, как именно должен быть реализован тот или иной std алгоритм. Дается только описание того, что на входе, что на выходе и асимптотические ограничения по времени работы и памяти. В статье я постарался прикинуть, какие математические алгоритмы и структуры данных имели ввиду авторы стандарта, указывая ограничения для той или иной сортировки и для некоторых других алгоритмов. А так же как эти алгоритмы реализованы на практике.\r\n\r\n\r\nПри написании статьи я использовал стандарт C++17. В качестве реализаций рассматривал GCC 10.1.0 (май 2020) и LLVM/Clang 10.0.0 (март 2020). В каждой и них есть своя реализация STL, а значит и std алгоритмов.', '<br>\r\n<p>Стандарт С++ почти никогда не указывает, как именно должен быть реализован тот или иной std алгоритм. Дается только описание того, что на входе, что на выходе и асимптотические ограничения по времени работы и памяти. В статье я постарался прикинуть, какие математические алгоритмы и структуры данных имели ввиду авторы стандарта, указывая ограничения для той или иной сортировки и для некоторых других алгоритмов. А так же как эти алгоритмы реализованы на практике.</p><br>\r\n<p>При написании статьи я использовал стандарт C++17. В качестве реализаций рассматривал GCC 10.1.0 (май 2020) и LLVM/Clang 10.0.0 (март 2020). В каждой и них есть своя реализация STL, а значит и std алгоритмов.</p><a name=\"habracut\"></a><br>\r\n<h2 id=\"1-odnopotochnye-realizacii\">1. Однопоточные реализации</h2><br>\r\n<h3 id=\"11-gotovye-sortirovki\">1.1. Готовые сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::sort()</strong>. Еще в стандарте C++98/C++03 мы видим, что сложность алгоритма примерно n*log(n) сравнений. А также есть примечание, что если важна сложность в худшем случае, то следует использовать <code>std::stable_sort()</code> или <code>std::partial_sort()</code>. Похоже, что в качестве реализации <code>std::sort()</code> подразумевался <a href=\"https://en.wikipedia.org/wiki/Quicksort\">quicksort</a> (в худшем случае O(n<sup>2</sup>) сравнений). Однако, начиная с C++11 мы видим, что сложность <code>std::sort()</code> уже O(n*log(n)) сравнений безо всяких оговорок. GCC реализует предложенную в 1997 году <a href=\"https://en.wikipedia.org/wiki/Introsort\">introsort</a> (O(n*log(n)) сравнений, как в среднем, так и в худшем случае). Introsort сначала сортирует как quicksort, но вскоре переключается на <a href=\"https://en.wikipedia.org/wiki/Heapsort\">heapsort</a> и в самом конце сортировки, когда остаются небольшие интервалы (в случае GCC менее 16 элементов), сортирует их при помощи <a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">insertion sort</a>. А вот LLVM реализует весьма сложный алгоритм с множеством оптимизаций в зависимости от размеров сортируемых интервалов и того, являются ли сортируемые элементы тривиально копируемыми и тривиально конструируемыми.</li>\r\n<li><strong>std::partial_sort()</strong>. Поиск некоторого числа элементов с минимальным значением из множества элементов и их сортировка. Во всех версиях стандарта сложность примерно n*log(m) сравнений, где n — количество элементов в контейнере, а m — количество минимальных элементов, которое нужно найти. Задача для heapsort. Сложность в точности совпадает с этим алгоритмом. Так и реализовано в LLVM и GCC.</li>\r\n<li><strong>std::stable_sort()</strong>. Тут немного сложнее. Во-первых, в отличии от предыдущих сортировок в стандарте отмечено, что она стабильная. Т.е. не меняет местами эквивалентные элементы при сортировке. Во-вторых, сложность ее в худшем случае n*(log(n))<sup>2</sup> сравнений. Но если достаточно памяти, то должно быть n*log(n) сравнений. Т.е. имеется ввиду 2 разных алгоритма стабильной сортировки. В варианте, когда памяти много подходит стандартный <a href=\"https://en.wikipedia.org/wiki/Merge_sort\">merge sort</a>. Как раз ему требуется дополнительная память для работы. Сделать merge sort без дополнительной памяти за O(n*log(n)) сравнений так же возможно. Но это сложный алгоритм и не смотря на асимптотику n*log(n) сравнений константа у него велика, и в обычных условиях он будет работать не очень быстро. Поэтому обычно используется вариант merge sort без дополнительной памяти, который имеет асимптотику n*(log(n))<sup>2</sup> сравнений. И в GCC и в LLVM реализации в целом похожи. Реализованы оба алгоритма: один работает при наличии памяти, другой — когда памяти не хватает. Обе реализации, когда дело доходит до небольших интервалов, используют insertion sort. Она стабильная и не требует дополнительной памяти. Но ее сложность O (n<sup>2</sup>) сравнений, что не играет роли на маленьких интервалах.</li>\r\n<li><strong>std::list::sort(), std::forward_list::sort()</strong>. Все перечисленные выше сортировки требуют итераторы произвольного доступа для задания сортируемого интервала. А что если требуется отсортировать контейнер, который не обеспечивает таких итераторов? Например, <code>std::list</code> или <code>std::forward_list</code>. У этих контейнеров есть специальный метод <code>sort()</code>. Согласно стандарту, он должен обеспечить стабильную сортировку за примерно n*log(n) сравнений, где n число элементов контейнера. В целом вполне подходит merge sort. Ее и реализуют GCC и LLVM и для <code>std::list::sort()</code>, и для <code>std::forward_list::sort()</code>. Но зачем вообще потребовались частные реализации сортировки для списков? Почему бы для <code>std::stable_sort()</code> просто не ослабить итераторы до однонаправленных или хотя бы двунаправленных, чтоб этот алгоритм можно было применять и к спискам? Дело в том, что в <code>std::stable_sort()</code> используются оптимизации, которые требуют итераторы произвольного доступа. Например, как я писал выше, когда дело доходит до сортировки небольших интервалов в <code>std::stable_sort()</code> разумно переключиться на insertion sort, а эта сортировка требует итераторы произвольного доступа.</li>\r\n<li><strong>std::make_heap(), std::sort_heap()</strong>. Алгоритмы по работе с кучей (max heap), включая сортировку. <code>std::sort_heap()</code> это единственный способ сортировки, алгоритм для которого указан явно. Сортировка должна быть реализована, как heapsort. Так и реализовано в LLVM и GCC.</li>\r\n</ul><br>\r\n<p><strong>Сводная таблица</strong></p><br>\r\n<div class=\"scrollable-table\"><table>\r\n<thead>\r\n<tr>\r\n<th>Алгоритм</th>\r\n<th>Сложность согласно стандарту C++17</th>\r\n<th>Реализация в GCC</th>\r\n<th>Реализация в LLVM/Clang</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>std::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>introsort</td>\r\n<td>-</td>\r\n</tr>\r\n<tr>\r\n<td>std::partial_sort()</td>\r\n<td>O(n*log(m))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n<tr>\r\n<td>std::stable_sort()</td>\r\n<td>O(n*log(n))/O(n*(log(n))<sup>2</sup>)</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::list::sort(), std::forward_list::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::make_heap(), std::sort_heap()</td>\r\n<td>O(n*log(n))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n</tbody>\r\n</table></div><br>\r\n<p><em>Примечание. В качестве реализации в GCC и LLVM указан алгоритм, который используется для больших сортируемых интервалов. Для особых случаев (небольшие интервалы и т.п.) часто используются оптимизации.<br>\r\n</em></p><br>\r\n<h3 id=\"12-sostavlyayuschie-algoritmov-sortirovki\">1.2. Составляющие алгоритмов сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::merge()</strong>. Слияние двух сортированных интервалов. Этот алгоритм не меняет местами эквивалентные элементы, т.е. он стабильный. Количество сравнений не более, чем сумма длин сливаемых интервалов минус 1. На базе данного алгоритма очень просто реализовать merge sort. Однако напрямую этот алгоритм не используется в <code>std::stable_sort()</code> ни LLVM, ни в GCC. Для шага слияния в <code>std::stable_sort()</code> написаны отдельные реализации.</li>\r\n<li><strong>std::inplace_merge()</strong>. Этот алгоритм также реализует слияние двух сортированных интервалов и он также стабильный. У него есть интерфейсные отличия от <code>std::merge()</code>, но кроме них есть еще одно, очень важное. По сути <code>std::inplace_merge()</code> это два алгоритма. Один вызывается при наличии достаточного количества дополнительной памяти. Его сложность, как и в случае <code>std::merge()</code>, не более чем сумма длин объединяемых интервалов минус 1. А другой, если дополнительной памяти нет и нужно сделать слияние &quot;in place&quot;. Сложность этого &quot;in place&quot; алгоритма n*log(n) сравнений, где n сумма элементов в сливаемых интервалах. Все это очень напоминает <code>std::stable_sort()</code>, и это неспроста. Как кажется, авторы стандарта предполагали использование <code>std::inplace_merge()</code> или подобных алгоритмов в <code>std::stable_sort()</code>. Эту идею отражают реализации. В LLVM для реализации <code>std::stable_sort()</code> используется <code>std::inplace_merge()</code>, в GCC для реализаций <code>std::stable_sort()</code> и <code>std::inplace_merge()</code> используются некоторые общие методы.</li>\r\n<li><strong>std::partition()/std::stable_partition()</strong>. Данные алгоритмы также можно использовать для написания сортировок. Например, для quicksort или introsort. Но ни GCC ни LLVM не использует их напрямую для реализации сортировок. Используются аналогичные им, но оптимизированные, для случая конкретной сортировки, варианты реализации.</li>\r\n</ul><br>\r\n<h2 id=\"2-mnogopotochnye-realizacii\">2. Многопоточные реализации</h2><br>\r\n<p>В C++17 для многих алгоритмов появилась возможность задавать политику исполнения (ExecutionPolicy). Она обычно указывается первым параметром алгоритма. Алгоритмы сортировок не стали исключением. Политику исполнения можно задать для большинства алгоритмов рассмотренных выше. В том числе и указать, что алгоритм может выполняться в несколько потоков (<code>std::execution::par</code>, <code>std::execution::par_unseq</code>). Это значит, что именно может, а не обязан. А будет вычисляться в несколько потоков или нет зависит от целевой платформы, реализации и варианта сборки компилятора. Асимптотическая сложность также остается неизменной, однако константа может оказаться меньше за счет использования многих потоков.</p><br>\r\n<p>Тут ключевое слово «может». Дело в том, что однопоточные реализации, описанные выше, подходят для соответствующих алгоритмов, какая бы политика исполнения ни была задана. И однопоточные реализации часто используются на настоящий момент независимо от политики исполнения. Я рассмотрел следующие версии:</p><br>\r\n<ul>\r\n<li>LLVM/Clang (Apple clang version 11.0.3 (clang-1103.0.32.62)) и MacOS 10.15.4. В этом случае заголовочный файл execution не нашелся. Т.е. политику многопоточности задать не получится;</li>\r\n<li>LLVM/Clang 10.0.0 сборка из brew. Тот же результат, что и в случае Apple clang;</li>\r\n<li>GCC 10.1.0 — файл execution есть и политику задать можно. Но какая бы политика ни была задана, использоваться будет однопоточная версия. Для вызова многопоточной версии необходимо, чтобы был подключен файл tbb/tbb.h при компиляции на платформе Intel. А для этого должна быть установлена библиотека <a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Intel Threading Building Blocks</a> (TBB) и пути поиска заголовочных файлов были прописаны. Установлен ли TBB проверяется при помощи специальной команды в gcc: <code>__has_include(&lt;tbb/tbb.h&gt;)</code> в файле c++config.h. И если данный файл виден, то используется многопоточная версия написанная на базе Threading Building Blocks, а если нет, то последовательная. Про TBB немного подробнее ниже. Дополнительную информацию о поддержке компилятором параллельных вычислений, как впрочем и другой функциональности, можно посмотреть на <a href=\"https://en.cppreference.com/w/cpp/compiler_support\">cppreference.com</a>.</li>\r\n</ul><br>\r\n<h2 id=\"3-intel-threading-building-blocks\">3. Intel Threading Building Blocks</h2><br>\r\n<p>Чтоб стало возможным использовать многопоточные версии разных алгоритмов, на сегодня нужно использовать дополнительные библиотеку Threading Building Blocks, разрабатываемую Intel. Это несложно: </p><br>\r\n<ul>\r\n<li>Клонируем репозиторий Threading Building Blocks с <a href=\"https://github.com/oneapi-src/oneTBB\">https://github.com/oneapi-src/oneTBB</a></li>\r\n<li>Из корня запускаем make и ждем несколько минут пока компилируется TBB или make all и ждем пару часов, чтоб прошли еще и тесты</li>\r\n<li>Далее при компиляции указываем пути к includes (<code>-I oneTBB/include</code>) и к динамической библиотеке (у меня был такой путь <code>-L tbb/oneTBB/build/macos_intel64_clang_cc11.0.3_os10.15.4_release -ltbb</code>, т.к. я собирал TBB при помощи Apple clang version 11.0.3 на MacOS)</li>\r\n</ul><br>\r\n<h2 id=\"4-epilog\">4. Эпилог</h2><br>\r\n<p>Как кажется, когда комитет C++ описывает те или иные особенности языка в стандарте, он предполагает те или иные сценарии использования и те или иные алгоритмы реализации. Часто все развивается, как предполагалось. Иногда идет своим путем. Иногда не используется вовсе. Какие бы ни были реализации тех или иных алгоритмов или структур данных сегодня, завтра это может измениться. Измениться впрочем может и стандарт. Но меняясь, стандарт почти всегда обеспечивает совместимость с ранее написанным кодом. При выпуске новых версий компиляторов могут меняться и реализации. Но изменяясь они предполагают, что разработчики полагаются на стандарт. На мой взгляд, имеет смысл понимать, как обычно реализуются те или иные части стандартной библиотеки. Но полагаться при разработке нужно именно на ограничения, заданные стандартом.</p><br>\r\n<p><strong>Ссылки на упомянутые алгоритмы и библиотеку:</strong></p><br>\r\n<ul>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Quicksort\">Quicksort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Introsort\">Introsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">Insertion Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Heapsort\">Heapsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Merge_sort\">Merge Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Threading Building Blocks</a></li>\r\n</ul><br>', 1, NULL);
INSERT INTO `articles` (`id`, `title`, `author`, `datepublished`, `img`, `description`, `content`, `active`, `datalastedit`) VALUES
(11, '7 странных особенностей Go', 'SkillFactory', '2020-10-01', 'https://habrastorage.org/webt/pv/7d/5v/pv7d5vs-ttnfrxjfkkzpoja3tdq.jpeg', 'Когда человек начинает писать на непривычном языке программирования, он всегда обращает внимание на его особенности. Новичку бывает сложно понять причины такого дизайна языка. Своим студентам мы даем необходимый контекст, и постепенно они учатся программировать, учитывая и принимая то, что раньше выводило их из равновесия. Автор статьи разбирает особенности Go, которые смущают начинающих.\r\n\r\n\r\nСразу скажу, что эта статья: мое личное, полностью субъективное мнение. Список ниже — только небольшая выдержка без каких-либо критериев выбора. Для ясности расскажу о себе: у меня около 20 лет опыта работы, я работал с C, C++, Java, Scala, Python, R (если смотреть на R как на язык).\r\nЯ нахожу Go легким в изучении. Наверное, благодаря четко определенному замыслу, который устраняет особенности, подразумевающие сложный синтаксис. Так или иначе, я начинаю список.', '<br>\r\n<p>Стандарт С++ почти никогда не указывает, как именно должен быть реализован тот или иной std алгоритм. Дается только описание того, что на входе, что на выходе и асимптотические ограничения по времени работы и памяти. В статье я постарался прикинуть, какие математические алгоритмы и структуры данных имели ввиду авторы стандарта, указывая ограничения для той или иной сортировки и для некоторых других алгоритмов. А так же как эти алгоритмы реализованы на практике.</p><br>\r\n<p>При написании статьи я использовал стандарт C++17. В качестве реализаций рассматривал GCC 10.1.0 (май 2020) и LLVM/Clang 10.0.0 (март 2020). В каждой и них есть своя реализация STL, а значит и std алгоритмов.</p><a name=\"habracut\"></a><br>\r\n<h2 id=\"1-odnopotochnye-realizacii\">1. Однопоточные реализации</h2><br>\r\n<h3 id=\"11-gotovye-sortirovki\">1.1. Готовые сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::sort()</strong>. Еще в стандарте C++98/C++03 мы видим, что сложность алгоритма примерно n*log(n) сравнений. А также есть примечание, что если важна сложность в худшем случае, то следует использовать <code>std::stable_sort()</code> или <code>std::partial_sort()</code>. Похоже, что в качестве реализации <code>std::sort()</code> подразумевался <a href=\"https://en.wikipedia.org/wiki/Quicksort\">quicksort</a> (в худшем случае O(n<sup>2</sup>) сравнений). Однако, начиная с C++11 мы видим, что сложность <code>std::sort()</code> уже O(n*log(n)) сравнений безо всяких оговорок. GCC реализует предложенную в 1997 году <a href=\"https://en.wikipedia.org/wiki/Introsort\">introsort</a> (O(n*log(n)) сравнений, как в среднем, так и в худшем случае). Introsort сначала сортирует как quicksort, но вскоре переключается на <a href=\"https://en.wikipedia.org/wiki/Heapsort\">heapsort</a> и в самом конце сортировки, когда остаются небольшие интервалы (в случае GCC менее 16 элементов), сортирует их при помощи <a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">insertion sort</a>. А вот LLVM реализует весьма сложный алгоритм с множеством оптимизаций в зависимости от размеров сортируемых интервалов и того, являются ли сортируемые элементы тривиально копируемыми и тривиально конструируемыми.</li>\r\n<li><strong>std::partial_sort()</strong>. Поиск некоторого числа элементов с минимальным значением из множества элементов и их сортировка. Во всех версиях стандарта сложность примерно n*log(m) сравнений, где n — количество элементов в контейнере, а m — количество минимальных элементов, которое нужно найти. Задача для heapsort. Сложность в точности совпадает с этим алгоритмом. Так и реализовано в LLVM и GCC.</li>\r\n<li><strong>std::stable_sort()</strong>. Тут немного сложнее. Во-первых, в отличии от предыдущих сортировок в стандарте отмечено, что она стабильная. Т.е. не меняет местами эквивалентные элементы при сортировке. Во-вторых, сложность ее в худшем случае n*(log(n))<sup>2</sup> сравнений. Но если достаточно памяти, то должно быть n*log(n) сравнений. Т.е. имеется ввиду 2 разных алгоритма стабильной сортировки. В варианте, когда памяти много подходит стандартный <a href=\"https://en.wikipedia.org/wiki/Merge_sort\">merge sort</a>. Как раз ему требуется дополнительная память для работы. Сделать merge sort без дополнительной памяти за O(n*log(n)) сравнений так же возможно. Но это сложный алгоритм и не смотря на асимптотику n*log(n) сравнений константа у него велика, и в обычных условиях он будет работать не очень быстро. Поэтому обычно используется вариант merge sort без дополнительной памяти, который имеет асимптотику n*(log(n))<sup>2</sup> сравнений. И в GCC и в LLVM реализации в целом похожи. Реализованы оба алгоритма: один работает при наличии памяти, другой — когда памяти не хватает. Обе реализации, когда дело доходит до небольших интервалов, используют insertion sort. Она стабильная и не требует дополнительной памяти. Но ее сложность O (n<sup>2</sup>) сравнений, что не играет роли на маленьких интервалах.</li>\r\n<li><strong>std::list::sort(), std::forward_list::sort()</strong>. Все перечисленные выше сортировки требуют итераторы произвольного доступа для задания сортируемого интервала. А что если требуется отсортировать контейнер, который не обеспечивает таких итераторов? Например, <code>std::list</code> или <code>std::forward_list</code>. У этих контейнеров есть специальный метод <code>sort()</code>. Согласно стандарту, он должен обеспечить стабильную сортировку за примерно n*log(n) сравнений, где n число элементов контейнера. В целом вполне подходит merge sort. Ее и реализуют GCC и LLVM и для <code>std::list::sort()</code>, и для <code>std::forward_list::sort()</code>. Но зачем вообще потребовались частные реализации сортировки для списков? Почему бы для <code>std::stable_sort()</code> просто не ослабить итераторы до однонаправленных или хотя бы двунаправленных, чтоб этот алгоритм можно было применять и к спискам? Дело в том, что в <code>std::stable_sort()</code> используются оптимизации, которые требуют итераторы произвольного доступа. Например, как я писал выше, когда дело доходит до сортировки небольших интервалов в <code>std::stable_sort()</code> разумно переключиться на insertion sort, а эта сортировка требует итераторы произвольного доступа.</li>\r\n<li><strong>std::make_heap(), std::sort_heap()</strong>. Алгоритмы по работе с кучей (max heap), включая сортировку. <code>std::sort_heap()</code> это единственный способ сортировки, алгоритм для которого указан явно. Сортировка должна быть реализована, как heapsort. Так и реализовано в LLVM и GCC.</li>\r\n</ul><br>\r\n<p><strong>Сводная таблица</strong></p><br>\r\n<div class=\"scrollable-table\"><table>\r\n<thead>\r\n<tr>\r\n<th>Алгоритм</th>\r\n<th>Сложность согласно стандарту C++17</th>\r\n<th>Реализация в GCC</th>\r\n<th>Реализация в LLVM/Clang</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>std::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>introsort</td>\r\n<td>-</td>\r\n</tr>\r\n<tr>\r\n<td>std::partial_sort()</td>\r\n<td>O(n*log(m))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n<tr>\r\n<td>std::stable_sort()</td>\r\n<td>O(n*log(n))/O(n*(log(n))<sup>2</sup>)</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::list::sort(), std::forward_list::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::make_heap(), std::sort_heap()</td>\r\n<td>O(n*log(n))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n</tbody>\r\n</table></div><br>\r\n<p><em>Примечание. В качестве реализации в GCC и LLVM указан алгоритм, который используется для больших сортируемых интервалов. Для особых случаев (небольшие интервалы и т.п.) часто используются оптимизации.<br>\r\n</em></p><br>\r\n<h3 id=\"12-sostavlyayuschie-algoritmov-sortirovki\">1.2. Составляющие алгоритмов сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::merge()</strong>. Слияние двух сортированных интервалов. Этот алгоритм не меняет местами эквивалентные элементы, т.е. он стабильный. Количество сравнений не более, чем сумма длин сливаемых интервалов минус 1. На базе данного алгоритма очень просто реализовать merge sort. Однако напрямую этот алгоритм не используется в <code>std::stable_sort()</code> ни LLVM, ни в GCC. Для шага слияния в <code>std::stable_sort()</code> написаны отдельные реализации.</li>\r\n<li><strong>std::inplace_merge()</strong>. Этот алгоритм также реализует слияние двух сортированных интервалов и он также стабильный. У него есть интерфейсные отличия от <code>std::merge()</code>, но кроме них есть еще одно, очень важное. По сути <code>std::inplace_merge()</code> это два алгоритма. Один вызывается при наличии достаточного количества дополнительной памяти. Его сложность, как и в случае <code>std::merge()</code>, не более чем сумма длин объединяемых интервалов минус 1. А другой, если дополнительной памяти нет и нужно сделать слияние &quot;in place&quot;. Сложность этого &quot;in place&quot; алгоритма n*log(n) сравнений, где n сумма элементов в сливаемых интервалах. Все это очень напоминает <code>std::stable_sort()</code>, и это неспроста. Как кажется, авторы стандарта предполагали использование <code>std::inplace_merge()</code> или подобных алгоритмов в <code>std::stable_sort()</code>. Эту идею отражают реализации. В LLVM для реализации <code>std::stable_sort()</code> используется <code>std::inplace_merge()</code>, в GCC для реализаций <code>std::stable_sort()</code> и <code>std::inplace_merge()</code> используются некоторые общие методы.</li>\r\n<li><strong>std::partition()/std::stable_partition()</strong>. Данные алгоритмы также можно использовать для написания сортировок. Например, для quicksort или introsort. Но ни GCC ни LLVM не использует их напрямую для реализации сортировок. Используются аналогичные им, но оптимизированные, для случая конкретной сортировки, варианты реализации.</li>\r\n</ul><br>\r\n<h2 id=\"2-mnogopotochnye-realizacii\">2. Многопоточные реализации</h2><br>\r\n<p>В C++17 для многих алгоритмов появилась возможность задавать политику исполнения (ExecutionPolicy). Она обычно указывается первым параметром алгоритма. Алгоритмы сортировок не стали исключением. Политику исполнения можно задать для большинства алгоритмов рассмотренных выше. В том числе и указать, что алгоритм может выполняться в несколько потоков (<code>std::execution::par</code>, <code>std::execution::par_unseq</code>). Это значит, что именно может, а не обязан. А будет вычисляться в несколько потоков или нет зависит от целевой платформы, реализации и варианта сборки компилятора. Асимптотическая сложность также остается неизменной, однако константа может оказаться меньше за счет использования многих потоков.</p><br>\r\n<p>Тут ключевое слово «может». Дело в том, что однопоточные реализации, описанные выше, подходят для соответствующих алгоритмов, какая бы политика исполнения ни была задана. И однопоточные реализации часто используются на настоящий момент независимо от политики исполнения. Я рассмотрел следующие версии:</p><br>\r\n<ul>\r\n<li>LLVM/Clang (Apple clang version 11.0.3 (clang-1103.0.32.62)) и MacOS 10.15.4. В этом случае заголовочный файл execution не нашелся. Т.е. политику многопоточности задать не получится;</li>\r\n<li>LLVM/Clang 10.0.0 сборка из brew. Тот же результат, что и в случае Apple clang;</li>\r\n<li>GCC 10.1.0 — файл execution есть и политику задать можно. Но какая бы политика ни была задана, использоваться будет однопоточная версия. Для вызова многопоточной версии необходимо, чтобы был подключен файл tbb/tbb.h при компиляции на платформе Intel. А для этого должна быть установлена библиотека <a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Intel Threading Building Blocks</a> (TBB) и пути поиска заголовочных файлов были прописаны. Установлен ли TBB проверяется при помощи специальной команды в gcc: <code>__has_include(&lt;tbb/tbb.h&gt;)</code> в файле c++config.h. И если данный файл виден, то используется многопоточная версия написанная на базе Threading Building Blocks, а если нет, то последовательная. Про TBB немного подробнее ниже. Дополнительную информацию о поддержке компилятором параллельных вычислений, как впрочем и другой функциональности, можно посмотреть на <a href=\"https://en.cppreference.com/w/cpp/compiler_support\">cppreference.com</a>.</li>\r\n</ul><br>\r\n<h2 id=\"3-intel-threading-building-blocks\">3. Intel Threading Building Blocks</h2><br>\r\n<p>Чтоб стало возможным использовать многопоточные версии разных алгоритмов, на сегодня нужно использовать дополнительные библиотеку Threading Building Blocks, разрабатываемую Intel. Это несложно: </p><br>\r\n<ul>\r\n<li>Клонируем репозиторий Threading Building Blocks с <a href=\"https://github.com/oneapi-src/oneTBB\">https://github.com/oneapi-src/oneTBB</a></li>\r\n<li>Из корня запускаем make и ждем несколько минут пока компилируется TBB или make all и ждем пару часов, чтоб прошли еще и тесты</li>\r\n<li>Далее при компиляции указываем пути к includes (<code>-I oneTBB/include</code>) и к динамической библиотеке (у меня был такой путь <code>-L tbb/oneTBB/build/macos_intel64_clang_cc11.0.3_os10.15.4_release -ltbb</code>, т.к. я собирал TBB при помощи Apple clang version 11.0.3 на MacOS)</li>\r\n</ul><br>\r\n<h2 id=\"4-epilog\">4. Эпилог</h2><br>\r\n<p>Как кажется, когда комитет C++ описывает те или иные особенности языка в стандарте, он предполагает те или иные сценарии использования и те или иные алгоритмы реализации. Часто все развивается, как предполагалось. Иногда идет своим путем. Иногда не используется вовсе. Какие бы ни были реализации тех или иных алгоритмов или структур данных сегодня, завтра это может измениться. Измениться впрочем может и стандарт. Но меняясь, стандарт почти всегда обеспечивает совместимость с ранее написанным кодом. При выпуске новых версий компиляторов могут меняться и реализации. Но изменяясь они предполагают, что разработчики полагаются на стандарт. На мой взгляд, имеет смысл понимать, как обычно реализуются те или иные части стандартной библиотеки. Но полагаться при разработке нужно именно на ограничения, заданные стандартом.</p><br>\r\n<p><strong>Ссылки на упомянутые алгоритмы и библиотеку:</strong></p><br>\r\n<ul>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Quicksort\">Quicksort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Introsort\">Introsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">Insertion Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Heapsort\">Heapsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Merge_sort\">Merge Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Threading Building Blocks</a></li>\r\n</ul><br>', 1, NULL),
(16, 'Динамическая типизация — это не инструмент для разработки. Это чепуха (паршивая)', 'fillpackart', '2020-08-03', 'https://habrastorage.org/webt/bq/q0/mo/bqq0mokv478hrdetajp38csbq5m.png', 'В программировании очень много вещей, в которых я разбираюсь очень плохо. Настолько много, что меня иногда спрашивают — а в чем ты вообще разбираешься?\r\n\r\nЯ разбираюсь в типах и проектировании удобного и надежного АПИ. Но для доброй половины разрабов эти вещи ничего не значат. Потому что они используют динамическую типизацию, и понятия не имеют, какие проблемы и зачем я решаю.\r\n\r\nБольшую часть жизни я просто махал на них рукой и проходил мимо. Эти глупцы не понимают очевидных вещей, и я не нанимался разъяснять каждому js-нику, почему его код — это не разработка, а игрушечное прототипирование. Но время идёт, а количество идиотов вокруг и не думает уменьшаться, вместо того, чтобы всей своей фронтенд индустрией переехать наконец на статический тайпскрипт, эти ослы начинают использовать всякие кложуры, писать тонны тестов, и идти на все мыслимые ухищрения — лишь бы не разбираться в типах.\r\n\r\nВ мире очень много спорных вещей, когда в зависимости от того, что ты хочешь получить, правда переваливается с одной чаши весов на другую, не оставляя место никакой абсолютной истине в последней инстанции. Пару лет назад я уже писал о типизации, но тогда я был молодой, глупый и трусливый — у меня была позиция, но чтобы не показаться идиотом, я старательно спрятал её за философскими рассуждениями о том, как все вокруг сложно, и как трудно работать адептам разных моделей типизации вместе.', '<br>\r\n<p>Стандарт С++ почти никогда не указывает, как именно должен быть реализован тот или иной std алгоритм. Дается только описание того, что на входе, что на выходе и асимптотические ограничения по времени работы и памяти. В статье я постарался прикинуть, какие математические алгоритмы и структуры данных имели ввиду авторы стандарта, указывая ограничения для той или иной сортировки и для некоторых других алгоритмов. А так же как эти алгоритмы реализованы на практике.</p><br>\r\n<p>При написании статьи я использовал стандарт C++17. В качестве реализаций рассматривал GCC 10.1.0 (май 2020) и LLVM/Clang 10.0.0 (март 2020). В каждой и них есть своя реализация STL, а значит и std алгоритмов.</p><a name=\"habracut\"></a><br>\r\n<h2 id=\"1-odnopotochnye-realizacii\">1. Однопоточные реализации</h2><br>\r\n<h3 id=\"11-gotovye-sortirovki\">1.1. Готовые сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::sort()</strong>. Еще в стандарте C++98/C++03 мы видим, что сложность алгоритма примерно n*log(n) сравнений. А также есть примечание, что если важна сложность в худшем случае, то следует использовать <code>std::stable_sort()</code> или <code>std::partial_sort()</code>. Похоже, что в качестве реализации <code>std::sort()</code> подразумевался <a href=\"https://en.wikipedia.org/wiki/Quicksort\">quicksort</a> (в худшем случае O(n<sup>2</sup>) сравнений). Однако, начиная с C++11 мы видим, что сложность <code>std::sort()</code> уже O(n*log(n)) сравнений безо всяких оговорок. GCC реализует предложенную в 1997 году <a href=\"https://en.wikipedia.org/wiki/Introsort\">introsort</a> (O(n*log(n)) сравнений, как в среднем, так и в худшем случае). Introsort сначала сортирует как quicksort, но вскоре переключается на <a href=\"https://en.wikipedia.org/wiki/Heapsort\">heapsort</a> и в самом конце сортировки, когда остаются небольшие интервалы (в случае GCC менее 16 элементов), сортирует их при помощи <a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">insertion sort</a>. А вот LLVM реализует весьма сложный алгоритм с множеством оптимизаций в зависимости от размеров сортируемых интервалов и того, являются ли сортируемые элементы тривиально копируемыми и тривиально конструируемыми.</li>\r\n<li><strong>std::partial_sort()</strong>. Поиск некоторого числа элементов с минимальным значением из множества элементов и их сортировка. Во всех версиях стандарта сложность примерно n*log(m) сравнений, где n — количество элементов в контейнере, а m — количество минимальных элементов, которое нужно найти. Задача для heapsort. Сложность в точности совпадает с этим алгоритмом. Так и реализовано в LLVM и GCC.</li>\r\n<li><strong>std::stable_sort()</strong>. Тут немного сложнее. Во-первых, в отличии от предыдущих сортировок в стандарте отмечено, что она стабильная. Т.е. не меняет местами эквивалентные элементы при сортировке. Во-вторых, сложность ее в худшем случае n*(log(n))<sup>2</sup> сравнений. Но если достаточно памяти, то должно быть n*log(n) сравнений. Т.е. имеется ввиду 2 разных алгоритма стабильной сортировки. В варианте, когда памяти много подходит стандартный <a href=\"https://en.wikipedia.org/wiki/Merge_sort\">merge sort</a>. Как раз ему требуется дополнительная память для работы. Сделать merge sort без дополнительной памяти за O(n*log(n)) сравнений так же возможно. Но это сложный алгоритм и не смотря на асимптотику n*log(n) сравнений константа у него велика, и в обычных условиях он будет работать не очень быстро. Поэтому обычно используется вариант merge sort без дополнительной памяти, который имеет асимптотику n*(log(n))<sup>2</sup> сравнений. И в GCC и в LLVM реализации в целом похожи. Реализованы оба алгоритма: один работает при наличии памяти, другой — когда памяти не хватает. Обе реализации, когда дело доходит до небольших интервалов, используют insertion sort. Она стабильная и не требует дополнительной памяти. Но ее сложность O (n<sup>2</sup>) сравнений, что не играет роли на маленьких интервалах.</li>\r\n<li><strong>std::list::sort(), std::forward_list::sort()</strong>. Все перечисленные выше сортировки требуют итераторы произвольного доступа для задания сортируемого интервала. А что если требуется отсортировать контейнер, который не обеспечивает таких итераторов? Например, <code>std::list</code> или <code>std::forward_list</code>. У этих контейнеров есть специальный метод <code>sort()</code>. Согласно стандарту, он должен обеспечить стабильную сортировку за примерно n*log(n) сравнений, где n число элементов контейнера. В целом вполне подходит merge sort. Ее и реализуют GCC и LLVM и для <code>std::list::sort()</code>, и для <code>std::forward_list::sort()</code>. Но зачем вообще потребовались частные реализации сортировки для списков? Почему бы для <code>std::stable_sort()</code> просто не ослабить итераторы до однонаправленных или хотя бы двунаправленных, чтоб этот алгоритм можно было применять и к спискам? Дело в том, что в <code>std::stable_sort()</code> используются оптимизации, которые требуют итераторы произвольного доступа. Например, как я писал выше, когда дело доходит до сортировки небольших интервалов в <code>std::stable_sort()</code> разумно переключиться на insertion sort, а эта сортировка требует итераторы произвольного доступа.</li>\r\n<li><strong>std::make_heap(), std::sort_heap()</strong>. Алгоритмы по работе с кучей (max heap), включая сортировку. <code>std::sort_heap()</code> это единственный способ сортировки, алгоритм для которого указан явно. Сортировка должна быть реализована, как heapsort. Так и реализовано в LLVM и GCC.</li>\r\n</ul><br>\r\n<p><strong>Сводная таблица</strong></p><br>\r\n<div class=\"scrollable-table\"><table>\r\n<thead>\r\n<tr>\r\n<th>Алгоритм</th>\r\n<th>Сложность согласно стандарту C++17</th>\r\n<th>Реализация в GCC</th>\r\n<th>Реализация в LLVM/Clang</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>std::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>introsort</td>\r\n<td>-</td>\r\n</tr>\r\n<tr>\r\n<td>std::partial_sort()</td>\r\n<td>O(n*log(m))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n<tr>\r\n<td>std::stable_sort()</td>\r\n<td>O(n*log(n))/O(n*(log(n))<sup>2</sup>)</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::list::sort(), std::forward_list::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::make_heap(), std::sort_heap()</td>\r\n<td>O(n*log(n))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n</tbody>\r\n</table></div><br>\r\n<p><em>Примечание. В качестве реализации в GCC и LLVM указан алгоритм, который используется для больших сортируемых интервалов. Для особых случаев (небольшие интервалы и т.п.) часто используются оптимизации.<br>\r\n</em></p><br>\r\n<h3 id=\"12-sostavlyayuschie-algoritmov-sortirovki\">1.2. Составляющие алгоритмов сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::merge()</strong>. Слияние двух сортированных интервалов. Этот алгоритм не меняет местами эквивалентные элементы, т.е. он стабильный. Количество сравнений не более, чем сумма длин сливаемых интервалов минус 1. На базе данного алгоритма очень просто реализовать merge sort. Однако напрямую этот алгоритм не используется в <code>std::stable_sort()</code> ни LLVM, ни в GCC. Для шага слияния в <code>std::stable_sort()</code> написаны отдельные реализации.</li>\r\n<li><strong>std::inplace_merge()</strong>. Этот алгоритм также реализует слияние двух сортированных интервалов и он также стабильный. У него есть интерфейсные отличия от <code>std::merge()</code>, но кроме них есть еще одно, очень важное. По сути <code>std::inplace_merge()</code> это два алгоритма. Один вызывается при наличии достаточного количества дополнительной памяти. Его сложность, как и в случае <code>std::merge()</code>, не более чем сумма длин объединяемых интервалов минус 1. А другой, если дополнительной памяти нет и нужно сделать слияние &quot;in place&quot;. Сложность этого &quot;in place&quot; алгоритма n*log(n) сравнений, где n сумма элементов в сливаемых интервалах. Все это очень напоминает <code>std::stable_sort()</code>, и это неспроста. Как кажется, авторы стандарта предполагали использование <code>std::inplace_merge()</code> или подобных алгоритмов в <code>std::stable_sort()</code>. Эту идею отражают реализации. В LLVM для реализации <code>std::stable_sort()</code> используется <code>std::inplace_merge()</code>, в GCC для реализаций <code>std::stable_sort()</code> и <code>std::inplace_merge()</code> используются некоторые общие методы.</li>\r\n<li><strong>std::partition()/std::stable_partition()</strong>. Данные алгоритмы также можно использовать для написания сортировок. Например, для quicksort или introsort. Но ни GCC ни LLVM не использует их напрямую для реализации сортировок. Используются аналогичные им, но оптимизированные, для случая конкретной сортировки, варианты реализации.</li>\r\n</ul><br>\r\n<h2 id=\"2-mnogopotochnye-realizacii\">2. Многопоточные реализации</h2><br>\r\n<p>В C++17 для многих алгоритмов появилась возможность задавать политику исполнения (ExecutionPolicy). Она обычно указывается первым параметром алгоритма. Алгоритмы сортировок не стали исключением. Политику исполнения можно задать для большинства алгоритмов рассмотренных выше. В том числе и указать, что алгоритм может выполняться в несколько потоков (<code>std::execution::par</code>, <code>std::execution::par_unseq</code>). Это значит, что именно может, а не обязан. А будет вычисляться в несколько потоков или нет зависит от целевой платформы, реализации и варианта сборки компилятора. Асимптотическая сложность также остается неизменной, однако константа может оказаться меньше за счет использования многих потоков.</p><br>\r\n<p>Тут ключевое слово «может». Дело в том, что однопоточные реализации, описанные выше, подходят для соответствующих алгоритмов, какая бы политика исполнения ни была задана. И однопоточные реализации часто используются на настоящий момент независимо от политики исполнения. Я рассмотрел следующие версии:</p><br>\r\n<ul>\r\n<li>LLVM/Clang (Apple clang version 11.0.3 (clang-1103.0.32.62)) и MacOS 10.15.4. В этом случае заголовочный файл execution не нашелся. Т.е. политику многопоточности задать не получится;</li>\r\n<li>LLVM/Clang 10.0.0 сборка из brew. Тот же результат, что и в случае Apple clang;</li>\r\n<li>GCC 10.1.0 — файл execution есть и политику задать можно. Но какая бы политика ни была задана, использоваться будет однопоточная версия. Для вызова многопоточной версии необходимо, чтобы был подключен файл tbb/tbb.h при компиляции на платформе Intel. А для этого должна быть установлена библиотека <a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Intel Threading Building Blocks</a> (TBB) и пути поиска заголовочных файлов были прописаны. Установлен ли TBB проверяется при помощи специальной команды в gcc: <code>__has_include(&lt;tbb/tbb.h&gt;)</code> в файле c++config.h. И если данный файл виден, то используется многопоточная версия написанная на базе Threading Building Blocks, а если нет, то последовательная. Про TBB немного подробнее ниже. Дополнительную информацию о поддержке компилятором параллельных вычислений, как впрочем и другой функциональности, можно посмотреть на <a href=\"https://en.cppreference.com/w/cpp/compiler_support\">cppreference.com</a>.</li>\r\n</ul><br>\r\n<h2 id=\"3-intel-threading-building-blocks\">3. Intel Threading Building Blocks</h2><br>\r\n<p>Чтоб стало возможным использовать многопоточные версии разных алгоритмов, на сегодня нужно использовать дополнительные библиотеку Threading Building Blocks, разрабатываемую Intel. Это несложно: </p><br>\r\n<ul>\r\n<li>Клонируем репозиторий Threading Building Blocks с <a href=\"https://github.com/oneapi-src/oneTBB\">https://github.com/oneapi-src/oneTBB</a></li>\r\n<li>Из корня запускаем make и ждем несколько минут пока компилируется TBB или make all и ждем пару часов, чтоб прошли еще и тесты</li>\r\n<li>Далее при компиляции указываем пути к includes (<code>-I oneTBB/include</code>) и к динамической библиотеке (у меня был такой путь <code>-L tbb/oneTBB/build/macos_intel64_clang_cc11.0.3_os10.15.4_release -ltbb</code>, т.к. я собирал TBB при помощи Apple clang version 11.0.3 на MacOS)</li>\r\n</ul><br>\r\n<h2 id=\"4-epilog\">4. Эпилог</h2><br>\r\n<p>Как кажется, когда комитет C++ описывает те или иные особенности языка в стандарте, он предполагает те или иные сценарии использования и те или иные алгоритмы реализации. Часто все развивается, как предполагалось. Иногда идет своим путем. Иногда не используется вовсе. Какие бы ни были реализации тех или иных алгоритмов или структур данных сегодня, завтра это может измениться. Измениться впрочем может и стандарт. Но меняясь, стандарт почти всегда обеспечивает совместимость с ранее написанным кодом. При выпуске новых версий компиляторов могут меняться и реализации. Но изменяясь они предполагают, что разработчики полагаются на стандарт. На мой взгляд, имеет смысл понимать, как обычно реализуются те или иные части стандартной библиотеки. Но полагаться при разработке нужно именно на ограничения, заданные стандартом.</p><br>\r\n<p><strong>Ссылки на упомянутые алгоритмы и библиотеку:</strong></p><br>\r\n<ul>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Quicksort\">Quicksort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Introsort\">Introsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">Insertion Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Heapsort\">Heapsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Merge_sort\">Merge Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Threading Building Blocks</a></li>\r\n</ul><br>', 1, NULL),
(17, 'Юлия → Iuliia. Всё о транслитерации', 'nalgeon', '2020-10-05', 'https://habrastorage.org/webt/dc/xr/yd/dcxryd2pnhqg1jpw99lrecrm9ru.png', 'Транслитерация — это запись кириллических слов латиницей (Анна → Anna, Самара → Samara). Её используют в загранпаспортах, водительских удостоверениях, трансграничной доставке, библиотечных каталогах и множестве других международных процессов.\r\n\r\n\r\nТак вышло, что я недавно окунулся в эту тему, а в Википедии она раскрыта слабо. Поэтому расскажу, что к чему (спойлер — если вы думаете, что с транслитерацией всё плохо, то на самом деле всё ещё хуже).\r\n\r\n\r\nИ конечно, поскольку это Хабр — предложу open-source библиотеки для решения проблемы.', '<br>\r\n<p>Стандарт С++ почти никогда не указывает, как именно должен быть реализован тот или иной std алгоритм. Дается только описание того, что на входе, что на выходе и асимптотические ограничения по времени работы и памяти. В статье я постарался прикинуть, какие математические алгоритмы и структуры данных имели ввиду авторы стандарта, указывая ограничения для той или иной сортировки и для некоторых других алгоритмов. А так же как эти алгоритмы реализованы на практике.</p><br>\r\n<p>При написании статьи я использовал стандарт C++17. В качестве реализаций рассматривал GCC 10.1.0 (май 2020) и LLVM/Clang 10.0.0 (март 2020). В каждой и них есть своя реализация STL, а значит и std алгоритмов.</p><a name=\"habracut\"></a><br>\r\n<h2 id=\"1-odnopotochnye-realizacii\">1. Однопоточные реализации</h2><br>\r\n<h3 id=\"11-gotovye-sortirovki\">1.1. Готовые сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::sort()</strong>. Еще в стандарте C++98/C++03 мы видим, что сложность алгоритма примерно n*log(n) сравнений. А также есть примечание, что если важна сложность в худшем случае, то следует использовать <code>std::stable_sort()</code> или <code>std::partial_sort()</code>. Похоже, что в качестве реализации <code>std::sort()</code> подразумевался <a href=\"https://en.wikipedia.org/wiki/Quicksort\">quicksort</a> (в худшем случае O(n<sup>2</sup>) сравнений). Однако, начиная с C++11 мы видим, что сложность <code>std::sort()</code> уже O(n*log(n)) сравнений безо всяких оговорок. GCC реализует предложенную в 1997 году <a href=\"https://en.wikipedia.org/wiki/Introsort\">introsort</a> (O(n*log(n)) сравнений, как в среднем, так и в худшем случае). Introsort сначала сортирует как quicksort, но вскоре переключается на <a href=\"https://en.wikipedia.org/wiki/Heapsort\">heapsort</a> и в самом конце сортировки, когда остаются небольшие интервалы (в случае GCC менее 16 элементов), сортирует их при помощи <a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">insertion sort</a>. А вот LLVM реализует весьма сложный алгоритм с множеством оптимизаций в зависимости от размеров сортируемых интервалов и того, являются ли сортируемые элементы тривиально копируемыми и тривиально конструируемыми.</li>\r\n<li><strong>std::partial_sort()</strong>. Поиск некоторого числа элементов с минимальным значением из множества элементов и их сортировка. Во всех версиях стандарта сложность примерно n*log(m) сравнений, где n — количество элементов в контейнере, а m — количество минимальных элементов, которое нужно найти. Задача для heapsort. Сложность в точности совпадает с этим алгоритмом. Так и реализовано в LLVM и GCC.</li>\r\n<li><strong>std::stable_sort()</strong>. Тут немного сложнее. Во-первых, в отличии от предыдущих сортировок в стандарте отмечено, что она стабильная. Т.е. не меняет местами эквивалентные элементы при сортировке. Во-вторых, сложность ее в худшем случае n*(log(n))<sup>2</sup> сравнений. Но если достаточно памяти, то должно быть n*log(n) сравнений. Т.е. имеется ввиду 2 разных алгоритма стабильной сортировки. В варианте, когда памяти много подходит стандартный <a href=\"https://en.wikipedia.org/wiki/Merge_sort\">merge sort</a>. Как раз ему требуется дополнительная память для работы. Сделать merge sort без дополнительной памяти за O(n*log(n)) сравнений так же возможно. Но это сложный алгоритм и не смотря на асимптотику n*log(n) сравнений константа у него велика, и в обычных условиях он будет работать не очень быстро. Поэтому обычно используется вариант merge sort без дополнительной памяти, который имеет асимптотику n*(log(n))<sup>2</sup> сравнений. И в GCC и в LLVM реализации в целом похожи. Реализованы оба алгоритма: один работает при наличии памяти, другой — когда памяти не хватает. Обе реализации, когда дело доходит до небольших интервалов, используют insertion sort. Она стабильная и не требует дополнительной памяти. Но ее сложность O (n<sup>2</sup>) сравнений, что не играет роли на маленьких интервалах.</li>\r\n<li><strong>std::list::sort(), std::forward_list::sort()</strong>. Все перечисленные выше сортировки требуют итераторы произвольного доступа для задания сортируемого интервала. А что если требуется отсортировать контейнер, который не обеспечивает таких итераторов? Например, <code>std::list</code> или <code>std::forward_list</code>. У этих контейнеров есть специальный метод <code>sort()</code>. Согласно стандарту, он должен обеспечить стабильную сортировку за примерно n*log(n) сравнений, где n число элементов контейнера. В целом вполне подходит merge sort. Ее и реализуют GCC и LLVM и для <code>std::list::sort()</code>, и для <code>std::forward_list::sort()</code>. Но зачем вообще потребовались частные реализации сортировки для списков? Почему бы для <code>std::stable_sort()</code> просто не ослабить итераторы до однонаправленных или хотя бы двунаправленных, чтоб этот алгоритм можно было применять и к спискам? Дело в том, что в <code>std::stable_sort()</code> используются оптимизации, которые требуют итераторы произвольного доступа. Например, как я писал выше, когда дело доходит до сортировки небольших интервалов в <code>std::stable_sort()</code> разумно переключиться на insertion sort, а эта сортировка требует итераторы произвольного доступа.</li>\r\n<li><strong>std::make_heap(), std::sort_heap()</strong>. Алгоритмы по работе с кучей (max heap), включая сортировку. <code>std::sort_heap()</code> это единственный способ сортировки, алгоритм для которого указан явно. Сортировка должна быть реализована, как heapsort. Так и реализовано в LLVM и GCC.</li>\r\n</ul><br>\r\n<p><strong>Сводная таблица</strong></p><br>\r\n<div class=\"scrollable-table\"><table>\r\n<thead>\r\n<tr>\r\n<th>Алгоритм</th>\r\n<th>Сложность согласно стандарту C++17</th>\r\n<th>Реализация в GCC</th>\r\n<th>Реализация в LLVM/Clang</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>std::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>introsort</td>\r\n<td>-</td>\r\n</tr>\r\n<tr>\r\n<td>std::partial_sort()</td>\r\n<td>O(n*log(m))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n<tr>\r\n<td>std::stable_sort()</td>\r\n<td>O(n*log(n))/O(n*(log(n))<sup>2</sup>)</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::list::sort(), std::forward_list::sort()</td>\r\n<td>O(n*log(n))</td>\r\n<td>merge sort</td>\r\n<td>merge sort</td>\r\n</tr>\r\n<tr>\r\n<td>std::make_heap(), std::sort_heap()</td>\r\n<td>O(n*log(n))</td>\r\n<td>heapsort</td>\r\n<td>heapsort</td>\r\n</tr>\r\n</tbody>\r\n</table></div><br>\r\n<p><em>Примечание. В качестве реализации в GCC и LLVM указан алгоритм, который используется для больших сортируемых интервалов. Для особых случаев (небольшие интервалы и т.п.) часто используются оптимизации.<br>\r\n</em></p><br>\r\n<h3 id=\"12-sostavlyayuschie-algoritmov-sortirovki\">1.2. Составляющие алгоритмов сортировки</h3><br>\r\n<ul>\r\n<li><strong>std::merge()</strong>. Слияние двух сортированных интервалов. Этот алгоритм не меняет местами эквивалентные элементы, т.е. он стабильный. Количество сравнений не более, чем сумма длин сливаемых интервалов минус 1. На базе данного алгоритма очень просто реализовать merge sort. Однако напрямую этот алгоритм не используется в <code>std::stable_sort()</code> ни LLVM, ни в GCC. Для шага слияния в <code>std::stable_sort()</code> написаны отдельные реализации.</li>\r\n<li><strong>std::inplace_merge()</strong>. Этот алгоритм также реализует слияние двух сортированных интервалов и он также стабильный. У него есть интерфейсные отличия от <code>std::merge()</code>, но кроме них есть еще одно, очень важное. По сути <code>std::inplace_merge()</code> это два алгоритма. Один вызывается при наличии достаточного количества дополнительной памяти. Его сложность, как и в случае <code>std::merge()</code>, не более чем сумма длин объединяемых интервалов минус 1. А другой, если дополнительной памяти нет и нужно сделать слияние &quot;in place&quot;. Сложность этого &quot;in place&quot; алгоритма n*log(n) сравнений, где n сумма элементов в сливаемых интервалах. Все это очень напоминает <code>std::stable_sort()</code>, и это неспроста. Как кажется, авторы стандарта предполагали использование <code>std::inplace_merge()</code> или подобных алгоритмов в <code>std::stable_sort()</code>. Эту идею отражают реализации. В LLVM для реализации <code>std::stable_sort()</code> используется <code>std::inplace_merge()</code>, в GCC для реализаций <code>std::stable_sort()</code> и <code>std::inplace_merge()</code> используются некоторые общие методы.</li>\r\n<li><strong>std::partition()/std::stable_partition()</strong>. Данные алгоритмы также можно использовать для написания сортировок. Например, для quicksort или introsort. Но ни GCC ни LLVM не использует их напрямую для реализации сортировок. Используются аналогичные им, но оптимизированные, для случая конкретной сортировки, варианты реализации.</li>\r\n</ul><br>\r\n<h2 id=\"2-mnogopotochnye-realizacii\">2. Многопоточные реализации</h2><br>\r\n<p>В C++17 для многих алгоритмов появилась возможность задавать политику исполнения (ExecutionPolicy). Она обычно указывается первым параметром алгоритма. Алгоритмы сортировок не стали исключением. Политику исполнения можно задать для большинства алгоритмов рассмотренных выше. В том числе и указать, что алгоритм может выполняться в несколько потоков (<code>std::execution::par</code>, <code>std::execution::par_unseq</code>). Это значит, что именно может, а не обязан. А будет вычисляться в несколько потоков или нет зависит от целевой платформы, реализации и варианта сборки компилятора. Асимптотическая сложность также остается неизменной, однако константа может оказаться меньше за счет использования многих потоков.</p><br>\r\n<p>Тут ключевое слово «может». Дело в том, что однопоточные реализации, описанные выше, подходят для соответствующих алгоритмов, какая бы политика исполнения ни была задана. И однопоточные реализации часто используются на настоящий момент независимо от политики исполнения. Я рассмотрел следующие версии:</p><br>\r\n<ul>\r\n<li>LLVM/Clang (Apple clang version 11.0.3 (clang-1103.0.32.62)) и MacOS 10.15.4. В этом случае заголовочный файл execution не нашелся. Т.е. политику многопоточности задать не получится;</li>\r\n<li>LLVM/Clang 10.0.0 сборка из brew. Тот же результат, что и в случае Apple clang;</li>\r\n<li>GCC 10.1.0 — файл execution есть и политику задать можно. Но какая бы политика ни была задана, использоваться будет однопоточная версия. Для вызова многопоточной версии необходимо, чтобы был подключен файл tbb/tbb.h при компиляции на платформе Intel. А для этого должна быть установлена библиотека <a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Intel Threading Building Blocks</a> (TBB) и пути поиска заголовочных файлов были прописаны. Установлен ли TBB проверяется при помощи специальной команды в gcc: <code>__has_include(&lt;tbb/tbb.h&gt;)</code> в файле c++config.h. И если данный файл виден, то используется многопоточная версия написанная на базе Threading Building Blocks, а если нет, то последовательная. Про TBB немного подробнее ниже. Дополнительную информацию о поддержке компилятором параллельных вычислений, как впрочем и другой функциональности, можно посмотреть на <a href=\"https://en.cppreference.com/w/cpp/compiler_support\">cppreference.com</a>.</li>\r\n</ul><br>\r\n<h2 id=\"3-intel-threading-building-blocks\">3. Intel Threading Building Blocks</h2><br>\r\n<p>Чтоб стало возможным использовать многопоточные версии разных алгоритмов, на сегодня нужно использовать дополнительные библиотеку Threading Building Blocks, разрабатываемую Intel. Это несложно: </p><br>\r\n<ul>\r\n<li>Клонируем репозиторий Threading Building Blocks с <a href=\"https://github.com/oneapi-src/oneTBB\">https://github.com/oneapi-src/oneTBB</a></li>\r\n<li>Из корня запускаем make и ждем несколько минут пока компилируется TBB или make all и ждем пару часов, чтоб прошли еще и тесты</li>\r\n<li>Далее при компиляции указываем пути к includes (<code>-I oneTBB/include</code>) и к динамической библиотеке (у меня был такой путь <code>-L tbb/oneTBB/build/macos_intel64_clang_cc11.0.3_os10.15.4_release -ltbb</code>, т.к. я собирал TBB при помощи Apple clang version 11.0.3 на MacOS)</li>\r\n</ul><br>\r\n<h2 id=\"4-epilog\">4. Эпилог</h2><br>\r\n<p>Как кажется, когда комитет C++ описывает те или иные особенности языка в стандарте, он предполагает те или иные сценарии использования и те или иные алгоритмы реализации. Часто все развивается, как предполагалось. Иногда идет своим путем. Иногда не используется вовсе. Какие бы ни были реализации тех или иных алгоритмов или структур данных сегодня, завтра это может измениться. Измениться впрочем может и стандарт. Но меняясь, стандарт почти всегда обеспечивает совместимость с ранее написанным кодом. При выпуске новых версий компиляторов могут меняться и реализации. Но изменяясь они предполагают, что разработчики полагаются на стандарт. На мой взгляд, имеет смысл понимать, как обычно реализуются те или иные части стандартной библиотеки. Но полагаться при разработке нужно именно на ограничения, заданные стандартом.</p><br>\r\n<p><strong>Ссылки на упомянутые алгоритмы и библиотеку:</strong></p><br>\r\n<ul>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Quicksort\">Quicksort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Introsort\">Introsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Insertion_sort\">Insertion Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Heapsort\">Heapsort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Merge_sort\">Merge Sort</a></li>\r\n<li><a href=\"https://en.wikipedia.org/wiki/Threading_Building_Blocks\">Threading Building Blocks</a></li>\r\n</ul><br>', 1, NULL),
(18, 'Название какое-то/', 'Ванечка с весёлого посёлка/', '2015-07-20', 'https://habrastorage.org/webt/zd/39/s1/zd39s1gn6odxmxvkvhwkvprmsm0.gif', 'Тут будет какое-то описание./', 'По идее, должно быть содержимое./', 0, '2020-10-20');

-- --------------------------------------------------------

--
-- Table structure for table `categories`
--

CREATE TABLE `categories` (
  `id` int(10) UNSIGNED NOT NULL,
  `name` varchar(255) NOT NULL,
  `countarticleid` int(10) UNSIGNED NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- Dumping data for table `categories`
--

INSERT INTO `categories` (`id`, `name`, `countarticleid`) VALUES
(1, 'JavaScript', 2),
(2, 'React', 1),
(5, 'C++', 1),
(6, 'C', 0),
(7, 'Программирование', 6),
(8, 'Go', 0);

-- --------------------------------------------------------

--
-- Table structure for table `comments`
--

CREATE TABLE `comments` (
  `id` int(255) UNSIGNED NOT NULL,
  `articleid` int(255) UNSIGNED NOT NULL,
  `author` varchar(50) NOT NULL,
  `message` text NOT NULL,
  `status` tinyint(4) NOT NULL DEFAULT '0'
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- Dumping data for table `comments`
--

INSERT INTO `comments` (`id`, `articleid`, `author`, `message`, `status`) VALUES
(12, 4, 'lyadov', 'Hello World!', 1);

-- --------------------------------------------------------

--
-- Table structure for table `users`
--

CREATE TABLE `users` (
  `id` int(10) UNSIGNED NOT NULL,
  `username` varchar(100) NOT NULL,
  `password` text NOT NULL,
  `role` int(10) UNSIGNED NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

--
-- Dumping data for table `users`
--

INSERT INTO `users` (`id`, `username`, `password`, `role`) VALUES
(1, 'pena', '$2y$10$oOKNOteyj8NbA7ZcZKuDL.krhtyMVxiNn36daI27VtZqU2gTFL5by', 1);

--
-- Indexes for dumped tables
--

--
-- Indexes for table `articlecategory`
--
ALTER TABLE `articlecategory`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `articles`
--
ALTER TABLE `articles`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `categories`
--
ALTER TABLE `categories`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `comments`
--
ALTER TABLE `comments`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `users`
--
ALTER TABLE `users`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `articlecategory`
--
ALTER TABLE `articlecategory`
  MODIFY `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=90;

--
-- AUTO_INCREMENT for table `articles`
--
ALTER TABLE `articles`
  MODIFY `id` int(255) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=107;

--
-- AUTO_INCREMENT for table `categories`
--
ALTER TABLE `categories`
  MODIFY `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=9;

--
-- AUTO_INCREMENT for table `comments`
--
ALTER TABLE `comments`
  MODIFY `id` int(255) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=21;

--
-- AUTO_INCREMENT for table `users`
--
ALTER TABLE `users`
  MODIFY `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=2;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
